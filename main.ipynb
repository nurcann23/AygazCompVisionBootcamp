{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNwMtuvWeUVqD6nJ2ajqhta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nurcann23/AygazCompVisionBootcamp/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sizin gösterdiğiniz şekilde data kaynaktan indirildi."
      ],
      "metadata": {
        "id": "jaAA-kc4ajnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import kagglehub\n",
        "rrebirrth_animals_with_attributes_2_path = kagglehub.dataset_download('rrebirrth/animals-with-attributes-2')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "BRyxpkRURsyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c00dee5-f983-421a-de9b-984afd98b8c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rrebirrth/animals-with-attributes-2?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.0G/13.0G [10:19<00:00, 22.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Yine sizin verdiğiniz kod ile dosyalardaki gerekli resimlerin path'leri dictionary'ye kaydedildi. Kod her hayvandan ilk 650 resmi alacak şekilde modifiye edildi."
      ],
      "metadata": {
        "id": "MgbM2YG1bldA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Initialize the dictionary to hold paths for each animal\n",
        "image_paths = {}\n",
        "\n",
        "# Base directory for your dataset\n",
        "base_path = \"/root/.cache/kagglehub/datasets/rrebirrth/animals-with-attributes-2/versions/1/Animals_with_Attributes2/JPEGImages/\"\n",
        "\n",
        "# List of animals to search for\n",
        "animals = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"]\n",
        "\n",
        "# Traverse the directory structure\n",
        "for dirname, _, filenames in os.walk(base_path):\n",
        "    for animal in animals:\n",
        "        # Check if the current directory contains the animal's name\n",
        "        if animal in dirname:\n",
        "            # Initialize the list if the animal is encountered for the first time\n",
        "            if animal not in image_paths:\n",
        "                image_paths[animal] = []\n",
        "            # Add all image paths for the current animal\n",
        "            i = 0;\n",
        "            for filename in filenames:\n",
        "                if i < 650:\n",
        "                    image_paths[animal].append(os.path.join(dirname, filename))\n",
        "                    i += 1\n",
        "                else:\n",
        "                    break\n"
      ],
      "metadata": {
        "id": "Lvz--m-stQGC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tüm resimler aynı boyuta getirildi ve normalized edildi. Burada normalde hakim olduğum OpenCV'yi kullanmıştım ama GPU kullanımını sağlayabilmek için tensorflow kullandım.\n",
        "- Augmentation için daha önce Computer Vision dersimde yazmış olduğum add_salt_pepper_noise algoritmasını kullandım. Resimlere noise (resimlerin 15% kısmı noise olacak şekilde) ekleyerek datasetine ekledim."
      ],
      "metadata": {
        "id": "ntSBy2MkeOmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def add_salt_pepper_noise(image):\n",
        "\n",
        "    salt_pepper_image = image.copy()\n",
        "    rows, cols, _ = salt_pepper_image.shape\n",
        "\n",
        "    for x in range(rows):\n",
        "        for y in range(cols):\n",
        "            noisy_or_not = np.random.random()\n",
        "            if noisy_or_not < 0.15:\n",
        "                black_or_white = np.random.random()\n",
        "                salt_pepper_image[x, y] = 0 if black_or_white < 0.5 else 255\n",
        "\n",
        "    return salt_pepper_image\n",
        "\n",
        "normalized_data = []\n",
        "\n",
        "for animal, paths in image_paths.items():\n",
        "    for img_path in paths:\n",
        "        img_raw = tf.io.read_file(img_path)\n",
        "        img_tensor = tf.image.decode_jpeg(img_raw, channels=3)\n",
        "        img_resized = tf.image.resize(img_tensor, (128, 128))\n",
        "        img_resized_np = img_resized.numpy()\n",
        "\n",
        "        img_normalized = img_resized_np / 255.0\n",
        "        normalized_data.append((img_normalized, animal))\n",
        "\n",
        "        img_noisy = add_salt_pepper_noise(img_resized_np)\n",
        "        img_noisy_normalized = img_noisy / 255.0\n",
        "        normalized_data.append((img_noisy_normalized, animal))\n"
      ],
      "metadata": {
        "id": "03E8pk5Qtt7x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Task açıklamasında gösterildiği gibi resimler train ve test olarak ikiye ayrıldı."
      ],
      "metadata": {
        "id": "lvj1oFXPhFuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = [x[0] for x in normalized_data]\n",
        "y = [x[1] for x in normalized_data]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(\"Eğitim setindeki resim sayısı: \", len(X_train))\n",
        "print(\"Test setindeki resim sayısı: \", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrkZiLNltur_",
        "outputId": "2524aa36-3196-4de4-deb1-ced234543e32"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eğitim setindeki resim sayısı:  9100\n",
            "Test setindeki resim sayısı:  3900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bu modelde ilk olarak 16 filtreli bir Conv2D katmanıyla başladım ve daha karmaşık özellikleri öğrenebilmek için 64 ve 128 filtreli Conv2D katmanlarını ekleyerek devam ettim. Overfitting’i önlemek için Dropout katmanı ekledim. Modeli son halina getirmeden denemeler yaparak en yüksek doğruluğu yakaladığım halini kullandım."
      ],
      "metadata": {
        "id": "_L5Jtr-2AHw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "H7FCGrBAt0RA",
        "outputId": "81ef1c1f-d52d-4bfe-f906-a5474cc48ae2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m448\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m9,280\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m6,422,784\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,280</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,508,938\u001b[0m (24.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,508,938</span> (24.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,508,938\u001b[0m (24.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,508,938</span> (24.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Burada modelimi eğittim. Modelin performansı, validation data kullanılarak her epoch sonunda ölçüldü. Modelin accuracy değeri artarak güzel bir seviyeye ulaştı aynı şekilde noise eklenmiş datalar sayesinde val_accuracy değeri de önceki denemelerime göre oldukça arttı."
      ],
      "metadata": {
        "id": "zxsxgloSBLOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "class_mapping = {cls: i for i, cls in enumerate(animals)}\n",
        "y_train_enc = to_categorical([class_mapping[label] for label in y_train], num_classes=10)\n",
        "y_test_enc = to_categorical([class_mapping[label] for label in y_test], num_classes=10)\n",
        "\n",
        "model.fit(np.array(X_train), np.array(y_train_enc), epochs=10, validation_data=(np.array(X_test), np.array(y_test_enc)))\n"
      ],
      "metadata": {
        "id": "xlNP5t42t4Pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb8fecc3-cceb-484a-d465-5d1eb35b6378"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.2527 - loss: 2.0477 - val_accuracy: 0.4508 - val_loss: 1.5894\n",
            "Epoch 2/10\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4680 - loss: 1.5381 - val_accuracy: 0.5287 - val_loss: 1.3368\n",
            "Epoch 3/10\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.5610 - loss: 1.2661 - val_accuracy: 0.6038 - val_loss: 1.1734\n",
            "Epoch 4/10\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.6294 - loss: 1.0837 - val_accuracy: 0.6336 - val_loss: 1.0995\n",
            "Epoch 5/10\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.6936 - loss: 0.8981 - val_accuracy: 0.6749 - val_loss: 0.9463\n",
            "Epoch 6/10\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7487 - loss: 0.7409 - val_accuracy: 0.7164 - val_loss: 0.8362\n",
            "Epoch 7/10\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.7992 - loss: 0.5904 - val_accuracy: 0.7487 - val_loss: 0.8018\n",
            "Epoch 8/10\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8397 - loss: 0.4766 - val_accuracy: 0.7721 - val_loss: 0.7538\n",
            "Epoch 9/10\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8631 - loss: 0.3913 - val_accuracy: 0.8054 - val_loss: 0.6944\n",
            "Epoch 10/10\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9036 - loss: 0.2812 - val_accuracy: 0.8113 - val_loss: 0.6958\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ccb2dc64400>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bu kod parçasında adjust_brightness fonksiyonu kullanılarak her bir test resminin parlaklığıyla oynadım. Yeni bir test datası oluşturdum."
      ],
      "metadata": {
        "id": "kxpWb84ICDw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_manipulated_images(image, factor):\n",
        "    return tf.image.adjust_brightness(image, factor)\n",
        "\n",
        "manipulated_test_data = []\n",
        "for img, label in zip(X_test, y_test):\n",
        "    img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "    manipulated_img = get_manipulated_images(img_tensor, factor=0.2)\n",
        "    manipulated_test_data.append((manipulated_img.numpy(), label))\n"
      ],
      "metadata": {
        "id": "dy9mne1w7OC1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Manipüle edilen test verileri ile modeli test ettim ve doğruluk oranında bir düşüş gözlemledim. Model bu manipülasyona karşı çok sağlam değil."
      ],
      "metadata": {
        "id": "JPGQo_egCz2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "manipulated_X_test = [x[0] for x in manipulated_test_data]\n",
        "manipulated_y_test = [x[1] for x in manipulated_test_data]\n",
        "manipulated_y_test_enc = to_categorical(\n",
        "    [class_mapping[label] for label in manipulated_y_test], num_classes=10\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(\n",
        "    np.array(manipulated_X_test), np.array(manipulated_y_test_enc)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmpvz6AB7eXm",
        "outputId": "796a7aec-e278-4934-9abd-60e0617fccf3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6316 - loss: 1.2005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bu kodda, manipüle edilmiş test verilerine renk sabitleme işlemi uyguladım. get_wb_images fonksiyonu, her bir görüntü kanalını kendi ortalamasına bölerek renk dengesini sağlar ve renk sapmalarını azaltır. Manipüle edilmiş her görüntü işlenip yeni bir listeye eklenmiştir."
      ],
      "metadata": {
        "id": "om9SzCfeEOnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wb_images(image):\n",
        "\n",
        "    mean_r = tf.reduce_mean(image[:, :, 0])\n",
        "    mean_g = tf.reduce_mean(image[:, :, 1])\n",
        "    mean_b = tf.reduce_mean(image[:, :, 2])\n",
        "    balanced_image = tf.stack([\n",
        "        image[:, :, 0] / mean_r,\n",
        "        image[:, :, 1] / mean_g,\n",
        "        image[:, :, 2] / mean_b\n",
        "    ], axis=2)\n",
        "\n",
        "    balanced_image = tf.clip_by_value(balanced_image * 128, 0, 255)\n",
        "    return balanced_image\n",
        "\n",
        "wb_test_data = []\n",
        "for img, label in manipulated_test_data:\n",
        "    img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "    wb_img = get_wb_images(img_tensor)\n",
        "    wb_test_data.append((wb_img.numpy(), label))\n"
      ],
      "metadata": {
        "id": "h6HX6tw37mof"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model bu manipülasyonla daha da kötü bir sonuç verdi ve accuracy anlamadığım şekilde çok düştü."
      ],
      "metadata": {
        "id": "tAm49y10DqXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wb_X_test = [x[0] for x in wb_test_data]\n",
        "wb_y_test = [x[1] for x in wb_test_data]\n",
        "wb_y_test_enc = to_categorical(\n",
        "    [class_mapping[label] for label in wb_y_test], num_classes=10\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(\n",
        "    np.array(wb_X_test), np.array(wb_y_test_enc)\n",
        ")\n",
        "print(\"Renk Sabitliği Uygulanmış Test Verisi - Loss:\", loss)\n",
        "print(\"Renk Sabitliği Uygulanmış Test Verisi - Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kOAX31T7p8y",
        "outputId": "70b21fc6-7ae3-4931-c04d-cdd59c910de1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1986 - loss: 1024.6254\n",
            "Renk Sabitliği Uygulanmış Test Verisi - Loss: 1035.0372314453125\n",
            "Renk Sabitliği Uygulanmış Test Verisi - Accuracy: 0.1989743560552597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bu sonuçlar, modelin manipülasyonlar sonrası doğruluğunun düştüğünü muhtemel olarak overfitting olduğunu gösteriyor."
      ],
      "metadata": {
        "id": "FXYamYlZEbUL"
      }
    }
  ]
}